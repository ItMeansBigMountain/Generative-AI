{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain Examples \n",
    "- PineCone Vector database:  https://app.pinecone.io/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# secrets \n",
    "import constants\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] =  constants.APIKEY\n",
    "os.environ[\"OPENAI_ORGANIZATION_ID\"] = constants.ORGANIZATION_ID\n",
    "\n",
    "os.environ[\"PINECONE_API_KEY\"] =  constants.pinecone_api_key\n",
    "os.environ[\"PINECONE_ENV\"] = constants.pinecone_environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nThis works by allowing you to type in a question and then providing you with a response. It is a great way to learn more about a certain topic or to get help with a specific problem.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RUN LLM STRAIGHT UP \n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(model_name= \"text-davinci-003\")\n",
    "PROMPT = \"Hello, lets see how this works\"\n",
    "llm(f\"{PROMPT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Ah, Joker. I've been expecting you. What mischief are you up to this time?\", additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OPENAI MESSAGE HISTORY\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# init model\n",
    "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\")\n",
    "\n",
    "# message history\n",
    "messages = [\n",
    "    SystemMessage(content=\"i want you to act like a batman\" ),\n",
    "    HumanMessage(content=\"hello batman its me joker\")\n",
    "]\n",
    "\n",
    "# ai response\n",
    "response = chat(messages)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROMPT TEMPLATING\n",
    "\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "you are an expert data scientist with expertise in building machine learning ai models. Please plan out the coding project for {concept} in a couple of lines.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables = [\"concept\"],\n",
    "    template=template\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHAINS\n",
    "- Chains are LLM prompts that take inputs...\n",
    "- This allows for chains to <strong>link</strong> together....\n",
    "- Using one chain's output as another chain's input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m\n",
      "1. Gather data from existing datasets on neuroscience and marketing, such as customer behavior, market trends, and consumer preferences. \n",
      "\n",
      "2. Pre-process the data by cleaning, normalizing, and transforming it into a format that can be used in the model.\n",
      "\n",
      "3. Split the data into training and test sets.\n",
      "\n",
      "4. Select an appropriate machine learning model for the task and train it on the training data.\n",
      "\n",
      "5. Evaluate the modelâ€™s performance on the test data.\n",
      "\n",
      "6. Analyze the results and fine-tune the model to optimize performance.\n",
      "\n",
      "7. Deploy the trained model in a production environment.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m\n",
      "\n",
      "Gathering data from existing datasets is the first step in the process of using machine learning to gain insights from neuroscience and marketing data. This data could include information about customer behavior, market trends, and consumer preferences. After gathering the data, it is important to pre-process it. This can involve cleaning and normalizing it, transforming it into a format that can be used in the model, and splitting it into training and test sets. \n",
      "\n",
      "Once this is done, the next step is to select an appropriate machine learning model for the task and train it on the training data. This is done by showing the machine a lot of examples of the type of data it needs to analyze and by teaching it how to recognize patterns in it. After the model has been trained, it can then be evaluated on the test data to get a better idea of its performance. \n",
      "\n",
      "Once the model has been evaluated, the results can be analyzed and the model can be fine-tuned to optimize its performance. This could involve tweaking parameters or changing the type of model being used. Finally, the trained model can be deployed in a production environment so that it can be used to generate insights. \n",
      "\n",
      "In summary, machine learning is a powerful tool for gaining insights from\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "Gathering data from existing datasets is the first step in the process of using machine learning to gain insights from neuroscience and marketing data. This data could include information about customer behavior, market trends, and consumer preferences. After gathering the data, it is important to pre-process it. This can involve cleaning and normalizing it, transforming it into a format that can be used in the model, and splitting it into training and test sets. \n",
      "\n",
      "Once this is done, the next step is to select an appropriate machine learning model for the task and train it on the training data. This is done by showing the machine a lot of examples of the type of data it needs to analyze and by teaching it how to recognize patterns in it. After the model has been trained, it can then be evaluated on the test data to get a better idea of its performance. \n",
      "\n",
      "Once the model has been evaluated, the results can be analyzed and the model can be fine-tuned to optimize its performance. This could involve tweaking parameters or changing the type of model being used. Finally, the trained model can be deployed in a production environment so that it can be used to generate insights. \n",
      "\n",
      "In summary, machine learning is a powerful tool for gaining insights from\n"
     ]
    }
   ],
   "source": [
    "# LLM\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# TEMPLATING CHAINS\n",
    "from langchain.chains import LLMChain\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "# MERGE MULTIPLE CHAINS\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "\n",
    "# SELECT LLM\n",
    "llm = OpenAI(model_name= \"text-davinci-003\")  # Corrected model name\n",
    "\n",
    "# CREATE 2 PROMPT TEMPLATES\n",
    "prompt1 = PromptTemplate(\n",
    "    input_variables=[\"concept\"],\n",
    "    template = \"\"\"\n",
    "you are an expert data scientist with expertise in building machine learning ai models. Please plan out the coding project for {concept} in a couple of lines. Make sure to explain step by step.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "prompt2 = PromptTemplate(\n",
    "    input_variables=[\"ml_concept\"],\n",
    "    template = \"Turn the concept descrition of {ml_concept} and explain it to me like im five in a 1000 words.\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# CREATE CHAINS\n",
    "chain_one = LLMChain(llm=llm, prompt=prompt1)\n",
    "chain_two = LLMChain(llm=llm, prompt=prompt2)\n",
    "\n",
    "\n",
    "# MERGE CHAINS\n",
    "Merge_Chains = [chain_one, chain_two]\n",
    "overall_chain = SimpleSequentialChain(chains=Merge_Chains , verbose = True)\n",
    "\n",
    "\n",
    "# DISPLAY OUTPUT\n",
    "explaination = overall_chain.run(\"neuroscience applied marketing tricks\")\n",
    "print(explaination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EMBEDDINGS & VECTORE STORES\n",
    "- A vector (numeric) representation of text\n",
    "- Save embeddings of split text into 3RD party Vector Database using SDK\n",
    "\n",
    "\n",
    "\n",
    "_run `CHAINS` cells before observing_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m\n",
      "1. Collect and process data related to neuroscience applied marketing, including customer demographics, campaign performance, website analytics, and purchase data. \n",
      "\n",
      "2. Use exploratory data analysis to identify patterns and relationships in the data.\n",
      "\n",
      "3. Build a predictive model using machine learning algorithms such as logistic regression, decision trees, and random forests.\n",
      "\n",
      "4. Use the model to determine which customer segments should be targeted for marketing campaigns.\n",
      "\n",
      "5. Use the model to develop a marketing strategy, including tactics, content, and messaging.\n",
      "\n",
      "6. Test the marketing strategy to measure the impact of different tactics and refine the model accordingly.\n",
      "\n",
      "7. Analyze the results to identify areas for further optimization and develop insights to inform future campaigns.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m\n",
      "\n",
      "Marketing is a great way to get the word out about a product or service. It involves spreading the word to potential customers, which can be done in many ways such as through advertising, word of mouth, and using social media. To make sure that the marketing efforts are successful, it is important to collect data related to the target customer and the effectiveness of the marketing campaigns.\n",
      "\n",
      "In the case of neuroscience applied marketing, this data could include information about the customer demographics, such as age, gender, and location, as well as campaign performance data, website analytics, and purchase data. This data can then be used to identify patterns and relationships in the data using exploratory data analysis.\n",
      "\n",
      "Once the data has been collected and analyzed, a predictive model can then be built using machine learning algorithms such as logistic regression, decision trees, and random forests. These algorithms can be used to determine which customer segments should be targeted for marketing campaigns.\n",
      "\n",
      "With the predictive model in place, a marketing strategy can then be developed. This strategy should include tactics, content, and messaging that are tailored to each customer segment. The effectiveness of the strategy can then be tested to measure the impact of different tactics. If the results of the tests are not satisfactory, the\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Marketing is a great way to get the word out about a product or service. It involves spreading the', metadata={}),\n",
       " Document(page_content='word to potential customers, which can be done in many ways such as through advertising, word of', metadata={}),\n",
       " Document(page_content='mouth, and using social media. To make sure that the marketing efforts are successful, it is', metadata={}),\n",
       " Document(page_content='important to collect data related to the target customer and the effectiveness of the marketing', metadata={}),\n",
       " Document(page_content='campaigns.', metadata={}),\n",
       " Document(page_content='In the case of neuroscience applied marketing, this data could include information about the', metadata={}),\n",
       " Document(page_content='customer demographics, such as age, gender, and location, as well as campaign performance data,', metadata={}),\n",
       " Document(page_content='website analytics, and purchase data. This data can then be used to identify patterns and', metadata={}),\n",
       " Document(page_content='relationships in the data using exploratory data analysis.', metadata={}),\n",
       " Document(page_content='Once the data has been collected and analyzed, a predictive model can then be built using machine', metadata={}),\n",
       " Document(page_content='learning algorithms such as logistic regression, decision trees, and random forests. These', metadata={}),\n",
       " Document(page_content='algorithms can be used to determine which customer segments should be targeted for marketing', metadata={}),\n",
       " Document(page_content='campaigns.', metadata={}),\n",
       " Document(page_content='With the predictive model in place, a marketing strategy can then be developed. This strategy', metadata={}),\n",
       " Document(page_content='should include tactics, content, and messaging that are tailored to each customer segment. The', metadata={}),\n",
       " Document(page_content='effectiveness of the strategy can then be tested to measure the impact of different tactics. If the', metadata={}),\n",
       " Document(page_content='results of the tests are not satisfactory, the', metadata={})]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import  RecursiveCharacterTextSplitter\n",
    "\n",
    "# TAKE COMBINED CHAIN \n",
    "explaination = overall_chain.run(\"neuroscience applied marketing tricks\")\n",
    "\n",
    "# MAKE A SPLITTER OBJECT - SPLIT DATA INTO 100 CHUNKS OF TEXT\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 100,\n",
    "    chunk_overlap = 0,\n",
    ")\n",
    "\n",
    "# SPLIT OUR COMBINED LLM CHAIN\n",
    "texts = text_splitter.create_documents([explaination])\n",
    "\n",
    "\n",
    "# PRINT A SINGLE ITEM FROM SPLIT\n",
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\faree\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\embeddings\\openai.py:214: UserWarning: WARNING! model_name is not default parameter.\n",
      "                    model_name was transferred to model_kwargs.\n",
      "                    Please confirm that model_name is what you intended.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# EMBEDDING\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "# AVAILABLE EMBEDDINGS\n",
    "    # https://platform.openai.com/docs/guides/embeddings/what-are-embeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model_name=\"text-embedding-ada-002\")\n",
    "\n",
    "# embeddings.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='learning algorithms such as logistic regression, decision trees, and random forests. These', metadata={}),\n",
       " Document(page_content='learning algorithms such as logistic regression, decision trees, and random forests. These', metadata={}),\n",
       " Document(page_content='Once the data has been collected and analyzed, a predictive model can then be built using machine', metadata={}),\n",
       " Document(page_content='Once the data has been collected and analyzed, a predictive model can then be built using machine', metadata={})]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SAVE TO PINECONE VECTOR DATABASE\n",
    "import pinecone as pvdb\n",
    "from langchain.vectorstores import Pinecone\n",
    "\n",
    "\n",
    "# INIT PINECONE CLIENT\n",
    "pvdb.init(\n",
    "    api_key = os.environ['PINECONE_API_KEY'],\n",
    "    environment = os.environ['PINECONE_ENV']\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# SAVE INTO DB\n",
    "index_name = \"langchain-quickstart\"\n",
    "if index_name not in pvdb.list_indexes():\n",
    "    # we create a new index\n",
    "    pvdb.create_index(\n",
    "      name=index_name,\n",
    "      metric='cosine',\n",
    "      dimension=1536  \n",
    ")\n",
    "\n",
    "\n",
    "# SEARCH DATABASE OBJECT\n",
    "search = Pinecone.from_documents(\n",
    "    texts,\n",
    "    embeddings,\n",
    "    index_name=index_name\n",
    ")\n",
    "\n",
    "\n",
    "query = \"What is magical about machine learning?\"\n",
    "result = search.similarity_search(query=query)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AGENTS\n",
    "- runs tools that we import to help extend the LLM's abilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python REPL can execute arbitrary code. Use with caution.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m I need to solve a quadratic equation\n",
      "Action: Python_REPL\n",
      "Action Input: from scipy.optimize import root\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to define the function\n",
      "Action: Python_REPL\n",
      "Action Input: def f(x): return 3 * x**2 + 2*x -1\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to find the roots of the function\n",
      "Action: Python_REPL\n",
      "Action Input: root(f, [0, 1])\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: The roots of the quadratic function 3 * x**2 + 2*x -1 are -1.0 and 0.3333333333333333.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The roots of the quadratic function 3 * x**2 + 2*x -1 are -1.0 and 0.3333333333333333.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents.agent_toolkits import create_python_agent\n",
    "from langchain.tools.python.tool import PythonREPLTool\n",
    "from langchain.python import PythonREPL\n",
    "from langchain.llms.openai import OpenAI\n",
    "\n",
    "# CREATE AGENT EXECUTOR\n",
    "agent_executor = create_python_agent(\n",
    "    llm=OpenAI(temperature=0,max_tokens=1000),\n",
    "    tool=PythonREPLTool(),\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "agent_executor.run(\"Find the roots (zeros) if the quadratic function 3 * x**2 + 2*x -1\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
