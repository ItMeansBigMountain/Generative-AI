# START LLM GUI
- `./oogabooga_windows/start_windows.bat` 
    - Click on the start_windows.bat file to run a server locally that will display the GUI

# Import a Model
- on the GUI click on "models" and download a model using the LLM models name as a string param
    - Vicuna 13B 1.1 4Bit model: https://huggingface.co/TheBloke/vicuna-13B-1.1-GPTQ

    - GPT4-x-Alpaca model: https://huggingface.co/anon8231489123/gpt4-x-alpaca-13b-native-4bit-128g

    - Pygmalion model: https://huggingface.co/mayaeary/pygmalion-6b_dev-4bit-128g

    - Monero Pygmalion model: https://huggingface.co/Monero/Pygmalion-Metharme-7b-4bit-TopScore

    - LLAMA 2 13B: https://huggingface.co/TheBloke/Llama-2-13B-chat-GPTQ
    
    - palmyra-small: https://huggingface.co/Writer/palmyra-small
    




-  Models are saved in `~.\LLM\oobabooga_windows\text-generation-webui\models`


### Select model
- sometimes youll need to click the reload button to refresh models list


# OOGA-BOOGA instructions
- go to https://github.com/oobabooga/text-generation-webui
- in the readme.md, find One-click installers
- choose windows and extract zip



_remember to take your time lol_